{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1840537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tweepy\n",
    "# ! pip install random-word\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from random_word import RandomWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a33cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAE1kaAEAAAAA5eq%2B9MQY1ZxmqsqI8hPhFTgXy%2BI%3DDiHeboF9HqPkABqkGhzUTegzzsJGvXvZNd0Op3kVi7TvZlhTMI\" \n",
    "consumer_key = \"kSuunUrf10tDwGT1PhNDWj4HY\"\n",
    "consumer_secret = \"Mg7Apz65TCxZqPhlnlQV8aBMuRhoDtFOljqbc3uoHp3F3uMzhh\"\n",
    "access_token = \"1239561788082933760-bUTmKDXfsLoBKlVBb3twda1jUkxQWK\"\n",
    "access_token_secret = \"jBxSnUcGx7l4OIfaGkIGmZQ6v3DAdq5tZyxmhP7J7w2dQ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f33fa",
   "metadata": {},
   "source": [
    "# Get Source Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17455a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(\n",
    "    bearer_token,\n",
    "    consumer_key,\n",
    "    consumer_secret,\n",
    "    access_token,\n",
    "    access_token_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d64fbbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current queries length: 0\n",
      "Current queries length: 15\n",
      "Current queries length: 23\n",
      "Current queries length: 33\n",
      "Current queries length: 45\n",
      "Current queries length: 64\n",
      "Current queries length: 74\n",
      "Current queries length: 87\n",
      "Current queries length: 98\n",
      "Current queries length: 116\n",
      "Current queries length: 116\n",
      "Current queries length: 125\n",
      "Current queries length: 142\n",
      "Current queries length: 157\n",
      "Current queries length: 164\n",
      "Current queries length: 174\n",
      "Current queries length: 186\n",
      "Current queries length: 196\n",
      "Current queries length: 203\n",
      "Current queries length: 210\n",
      "Current queries length: 225\n",
      "Current queries length: 231\n",
      "Current queries length: 243\n",
      "Current queries length: 254\n",
      "Current queries length: 261\n",
      "Current queries length: 270\n",
      "Current queries length: 282\n",
      "Current queries length: 292\n",
      "Current queries length: 303\n",
      "Current queries length: 314\n",
      "Current queries length: 324\n",
      "Current queries length: 334\n",
      "Current queries length: 341\n",
      "Current queries length: 344\n",
      "Current queries length: 353\n",
      "Current queries length: 357\n",
      "Current queries length: 363\n",
      "Current queries length: 370\n",
      "Current queries length: 382\n",
      "Current queries length: 394\n",
      "Current queries length: 408\n",
      "Current queries length: 416\n",
      "Current queries length: 424\n",
      "Current queries length: 431\n",
      "Current queries length: 437\n",
      "Current queries length: 441\n",
      "Current queries length: 451\n",
      "Current queries length: 459\n",
      "Current queries length: 467\n",
      "Current queries length: 474\n",
      "Current queries length: 482\n",
      "Current queries length: 490\n",
      "Current queries length: 502\n",
      "Current queries length: 513\n",
      "Current queries length: 519\n",
      "Current queries length: 524\n",
      "Current queries length: 531\n",
      "Current queries length: 542\n",
      "Current queries length: 553\n",
      "Current queries length: 564\n",
      "Current queries length: 579\n",
      "Current queries length: 586\n",
      "Current queries length: 595\n",
      "Current queries length: 608\n",
      "Current queries length: 615\n",
      "Current queries length: 621\n",
      "Current queries length: 633\n",
      "Current queries length: 641\n",
      "Current queries length: 645\n",
      "Current queries length: 655\n",
      "Current queries length: 664\n",
      "Current queries length: 670\n",
      "Current queries length: 676\n",
      "Current queries length: 681\n",
      "Current queries length: 690\n",
      "Current queries length: 696\n",
      "Current queries length: 700\n",
      "Current queries length: 707\n",
      "Current queries length: 712\n",
      "Current queries length: 720\n",
      "Current queries length: 726\n",
      "Current queries length: 731\n",
      "Current queries length: 737\n",
      "Current queries length: 747\n",
      "Current queries length: 754\n",
      "Current queries length: 766\n",
      "Current queries length: 774\n",
      "Current queries length: 779\n",
      "Current queries length: 789\n",
      "Current queries length: 798\n",
      "Current queries length: 804\n",
      "Current queries length: 811\n",
      "Current queries length: 817\n",
      "Current queries length: 823\n",
      "Current queries length: 825\n",
      "Current queries length: 833\n",
      "Current queries length: 839\n",
      "Current queries length: 849\n",
      "Current queries length: 853\n",
      "Current queries length: 859\n",
      "Current queries length: 865\n",
      "Current queries length: 874\n",
      "Current queries length: 883\n",
      "Current queries length: 889\n",
      "Current queries length: 891\n",
      "Current queries length: 897\n",
      "Current queries length: 903\n",
      "Current queries length: 910\n",
      "Current queries length: 910\n",
      "Current queries length: 915\n",
      "Current queries length: 925\n",
      "Current queries length: 933\n",
      "Current queries length: 942\n",
      "Current queries length: 947\n",
      "Current queries length: 955\n",
      "Current queries length: 962\n",
      "Current queries length: 969\n",
      "Current queries length: 973\n",
      "Current queries length: 985\n",
      "Current queries length: 989\n",
      "Current queries length: 993\n",
      "Current queries length: 999\n",
      "Get a query poll of length 1002. Sample queries ['stadium', 'mixture', 'authorities', 'machines', 'links', 'comprehensive', 'musicians', 'Jefferson', 'transaction', 'priorities']\n"
     ]
    }
   ],
   "source": [
    "# generate random word for queries\n",
    "n = 1000 # min number of queries\n",
    "queries = set()\n",
    "\n",
    "r = RandomWords()\n",
    "while len(queries) < n:\n",
    "    print(f\"Current queries length: {len(queries)}\")\n",
    "    temp = r.get_random_words(includePartOfSpeech=\"noun,verb\",\n",
    "                              minCorpusCount = 100000)\n",
    "    try:\n",
    "        queries = set().union(queries, temp)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "queries = list(queries)\n",
    "print(f\"Get a query poll of length {len(queries)}. Sample queries {queries[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7216017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from search result\n",
    "def CreateDataFrame(tweets):\n",
    "    id_list = [tweet.id for tweet in tweets[0]]\n",
    "    text_list = [tweet.text for tweet in tweets[0]]\n",
    "    non_hashtags_text_list = []\n",
    "    author_id_list = [tweet.author_id for tweet in tweets[0]]\n",
    "    hashtags_list = []\n",
    "    for tweet in tweets[0]:\n",
    "        try:\n",
    "            if tweet.entities.get(\"hashtags\"):\n",
    "                hashtags_list.append([t[\"tag\"] for t in tweet.entities.get(\"hashtags\")])\n",
    "                nontag_text = tweet.text\n",
    "                for t in tweet.entities.get(\"hashtags\"):\n",
    "                    nontag_text = nontag_text.replace(\"#\"+t[\"tag\"], \"<UNKTAG>\")\n",
    "                non_hashtags_text_list.append(nontag_text)\n",
    "            else:\n",
    "                hashtags_list.append([])\n",
    "                non_hashtags_text_list.append(tweet.text)\n",
    "        except:\n",
    "            hashtags_list.append([])\n",
    "            non_hashtags_text_list.append(tweet.text)\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": id_list,\n",
    "        \"text\": text_list,\n",
    "        \"non_hashtags_text\": non_hashtags_text_list,\n",
    "        \"author_id\": author_id_list,\n",
    "        \"hashtags\": hashtags_list\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7d45fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>non_hashtags_text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1512575901279608835</td>\n",
       "      <td>RT @PopBase: Las Vegas turned purple in honor ...</td>\n",
       "      <td>RT @PopBase: Las Vegas turned purple in honor ...</td>\n",
       "      <td>1079167585856282624</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1512575900684107783</td>\n",
       "      <td>He continues to recruit as much as possible an...</td>\n",
       "      <td>He continues to recruit as much as possible an...</td>\n",
       "      <td>86140975</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1512575894950457356</td>\n",
       "      <td>@Gianni2225 Funny how so many people proclaime...</td>\n",
       "      <td>@Gianni2225 Funny how so many people proclaime...</td>\n",
       "      <td>991448824647479296</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512575894841434122</td>\n",
       "      <td>RT @LCSOfficial: From 5-time Challenger to the...</td>\n",
       "      <td>RT @&lt;UNKTAG&gt;Official: From 5-time Challenger t...</td>\n",
       "      <td>2297906262</td>\n",
       "      <td>[LCS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1512575893796966406</td>\n",
       "      <td>RT @BTSMerchUpdates: ALLEGIANT STADIUM FOOD\\n\\...</td>\n",
       "      <td>RT @BTSMerchUpdates: ALLEGIANT STADIUM FOOD\\n\\...</td>\n",
       "      <td>894038577008574464</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1512575901279608835  RT @PopBase: Las Vegas turned purple in honor ...   \n",
       "1  1512575900684107783  He continues to recruit as much as possible an...   \n",
       "2  1512575894950457356  @Gianni2225 Funny how so many people proclaime...   \n",
       "3  1512575894841434122  RT @LCSOfficial: From 5-time Challenger to the...   \n",
       "4  1512575893796966406  RT @BTSMerchUpdates: ALLEGIANT STADIUM FOOD\\n\\...   \n",
       "\n",
       "                                   non_hashtags_text            author_id  \\\n",
       "0  RT @PopBase: Las Vegas turned purple in honor ...  1079167585856282624   \n",
       "1  He continues to recruit as much as possible an...             86140975   \n",
       "2  @Gianni2225 Funny how so many people proclaime...   991448824647479296   \n",
       "3  RT @<UNKTAG>Official: From 5-time Challenger t...           2297906262   \n",
       "4  RT @BTSMerchUpdates: ALLEGIANT STADIUM FOOD\\n\\...   894038577008574464   \n",
       "\n",
       "  hashtags  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3    [LCS]  \n",
       "4       []  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test dataframe from one query\n",
    "tweets = client.search_recent_tweets(query=queries[0], \n",
    "                                     tweet_fields=['author_id', 'entities'],\n",
    "                                     max_results=100)\n",
    "test_df = CreateDataFrame(tweets)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d50e4bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>non_hashtags_text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512575894841434122</td>\n",
       "      <td>RT @LCSOfficial: From 5-time Challenger to the...</td>\n",
       "      <td>RT @&lt;UNKTAG&gt;Official: From 5-time Challenger t...</td>\n",
       "      <td>2297906262</td>\n",
       "      <td>[LCS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1512575873613971458</td>\n",
       "      <td>RT @FOX5Vegas: #BTS doesn't kick off its Las V...</td>\n",
       "      <td>RT @FOX5Vegas: #&lt;UNKTAG&gt; doesn't kick off its ...</td>\n",
       "      <td>2482136157</td>\n",
       "      <td>[BTS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1512575873089683464</td>\n",
       "      <td>RT @BelhaimarJamal: #IbroxStadium home of @Ran...</td>\n",
       "      <td>RT @BelhaimarJamal: #&lt;UNKTAG&gt; home of @&lt;UNKTAG...</td>\n",
       "      <td>1299684274887634944</td>\n",
       "      <td>[IbroxStadium, RangersFC, GlasgowRangers, Glas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1512575863266631680</td>\n",
       "      <td>I‚Äôm selling Off my 2 #BTSTICKETS\\nField A1, Ro...</td>\n",
       "      <td>I‚Äôm selling Off my 2 #&lt;UNKTAG&gt;\\nField A1, Row ...</td>\n",
       "      <td>1411566745391976448</td>\n",
       "      <td>[BTSTICKETS, BTSTICKETSELLING, PTD_ON_STAGE_LA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1512575854609518592</td>\n",
       "      <td>RT @FOX5Vegas: #BTS mania has completely taken...</td>\n",
       "      <td>RT @FOX5Vegas: #&lt;UNKTAG&gt; mania has completely ...</td>\n",
       "      <td>1325256080272752641</td>\n",
       "      <td>[BTS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1512575851883204608</td>\n",
       "      <td>RT @News3LV: #BTS has taken over the Las Vegas...</td>\n",
       "      <td>RT @News3LV: #&lt;UNKTAG&gt; has taken over the Las ...</td>\n",
       "      <td>3039980481</td>\n",
       "      <td>[BTS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1512575841573744642</td>\n",
       "      <td>RT @brighttu0204: Still the best F4 intro..\\n\\...</td>\n",
       "      <td>RT @brighttu0204: Still the best F4 intro..\\n\\...</td>\n",
       "      <td>940934600255311872</td>\n",
       "      <td>[F4ThailandFinalEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1512575840860704770</td>\n",
       "      <td>Round üê∞üê∞üê∞üê∞üê∞\\nTomorrow, let‚Äôs have a great crow...</td>\n",
       "      <td>Round üê∞üê∞üê∞üê∞üê∞\\nTomorrow, let‚Äôs have a great crow...</td>\n",
       "      <td>3100779943</td>\n",
       "      <td>[ETR22, DTT22, BGS22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1512575797328224256</td>\n",
       "      <td>RT @FOX5Vegas: #BTS mania has completely taken...</td>\n",
       "      <td>RT @FOX5Vegas: #&lt;UNKTAG&gt; mania has completely ...</td>\n",
       "      <td>998193620233535488</td>\n",
       "      <td>[BTS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1512575781611913223</td>\n",
       "      <td>@AppleTV @mlb @nationals I live 5 miles from t...</td>\n",
       "      <td>@AppleTV @mlb @nationals I live 5 miles from t...</td>\n",
       "      <td>355850575</td>\n",
       "      <td>[terrible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1512575752138420225</td>\n",
       "      <td>RT @EncunSh: allegiant stadium nya beneran ged...</td>\n",
       "      <td>RT @EncunSh: allegiant stadium nya beneran ged...</td>\n",
       "      <td>4777208850</td>\n",
       "      <td>[BTS_THE_CITY_LasVegas, PTD_ON_STAGE_LV, BTSCO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1512575746870550539</td>\n",
       "      <td>One of the sickest things I‚Äôve ever been a par...</td>\n",
       "      <td>One of the sickest things I‚Äôve ever been a par...</td>\n",
       "      <td>786231858639974401</td>\n",
       "      <td>[RingTheBell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1512575743942807553</td>\n",
       "      <td>RT @FOX5Vegas: #BTS mania has completely taken...</td>\n",
       "      <td>RT @FOX5Vegas: #&lt;UNKTAG&gt; mania has completely ...</td>\n",
       "      <td>1247833465740914690</td>\n",
       "      <td>[BTS]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "3   1512575894841434122  RT @LCSOfficial: From 5-time Challenger to the...   \n",
       "19  1512575873613971458  RT @FOX5Vegas: #BTS doesn't kick off its Las V...   \n",
       "20  1512575873089683464  RT @BelhaimarJamal: #IbroxStadium home of @Ran...   \n",
       "24  1512575863266631680  I‚Äôm selling Off my 2 #BTSTICKETS\\nField A1, Ro...   \n",
       "30  1512575854609518592  RT @FOX5Vegas: #BTS mania has completely taken...   \n",
       "31  1512575851883204608  RT @News3LV: #BTS has taken over the Las Vegas...   \n",
       "36  1512575841573744642  RT @brighttu0204: Still the best F4 intro..\\n\\...   \n",
       "37  1512575840860704770  Round üê∞üê∞üê∞üê∞üê∞\\nTomorrow, let‚Äôs have a great crow...   \n",
       "60  1512575797328224256  RT @FOX5Vegas: #BTS mania has completely taken...   \n",
       "68  1512575781611913223  @AppleTV @mlb @nationals I live 5 miles from t...   \n",
       "89  1512575752138420225  RT @EncunSh: allegiant stadium nya beneran ged...   \n",
       "94  1512575746870550539  One of the sickest things I‚Äôve ever been a par...   \n",
       "95  1512575743942807553  RT @FOX5Vegas: #BTS mania has completely taken...   \n",
       "\n",
       "                                    non_hashtags_text            author_id  \\\n",
       "3   RT @<UNKTAG>Official: From 5-time Challenger t...           2297906262   \n",
       "19  RT @FOX5Vegas: #<UNKTAG> doesn't kick off its ...           2482136157   \n",
       "20  RT @BelhaimarJamal: #<UNKTAG> home of @<UNKTAG...  1299684274887634944   \n",
       "24  I‚Äôm selling Off my 2 #<UNKTAG>\\nField A1, Row ...  1411566745391976448   \n",
       "30  RT @FOX5Vegas: #<UNKTAG> mania has completely ...  1325256080272752641   \n",
       "31  RT @News3LV: #<UNKTAG> has taken over the Las ...           3039980481   \n",
       "36  RT @brighttu0204: Still the best F4 intro..\\n\\...   940934600255311872   \n",
       "37  Round üê∞üê∞üê∞üê∞üê∞\\nTomorrow, let‚Äôs have a great crow...           3100779943   \n",
       "60  RT @FOX5Vegas: #<UNKTAG> mania has completely ...   998193620233535488   \n",
       "68  @AppleTV @mlb @nationals I live 5 miles from t...            355850575   \n",
       "89  RT @EncunSh: allegiant stadium nya beneran ged...           4777208850   \n",
       "94  One of the sickest things I‚Äôve ever been a par...   786231858639974401   \n",
       "95  RT @FOX5Vegas: #<UNKTAG> mania has completely ...  1247833465740914690   \n",
       "\n",
       "                                             hashtags  \n",
       "3                                               [LCS]  \n",
       "19                                              [BTS]  \n",
       "20  [IbroxStadium, RangersFC, GlasgowRangers, Glas...  \n",
       "24  [BTSTICKETS, BTSTICKETSELLING, PTD_ON_STAGE_LA...  \n",
       "30                                              [BTS]  \n",
       "31                                              [BTS]  \n",
       "36                                [F4ThailandFinalEP]  \n",
       "37                              [ETR22, DTT22, BGS22]  \n",
       "60                                              [BTS]  \n",
       "68                                         [terrible]  \n",
       "89  [BTS_THE_CITY_LasVegas, PTD_ON_STAGE_LV, BTSCO...  \n",
       "94                                      [RingTheBell]  \n",
       "95                                              [BTS]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetTaggedTweet(tweet_df):\n",
    "    tagged_df = tweet_df[[ht != [] and ht != \"[]\" for ht in tweet_df[\"hashtags\"]]]\n",
    "    return tagged_df\n",
    "\n",
    "GetTaggedTweet(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3820d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process the data for index = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:50<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Get a whole dataset of length 9999\n",
      "  Get a tagged dataset of length 1487\n",
      "  Output the data...\n",
      "Process the data for index = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:50<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Get a whole dataset of length 19999\n",
      "  Get a tagged dataset of length 3002\n",
      "  Output the data...\n",
      "Process the data for index = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:50<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Get a whole dataset of length 29999\n",
      "  Get a tagged dataset of length 4631\n",
      "  Output the data...\n"
     ]
    }
   ],
   "source": [
    "# create the dataframe\n",
    "df_list = []\n",
    "tagged_df_list = []\n",
    "queries_list = []\n",
    "for i in range(10):\n",
    "    queries_list.append(queries[100*i: 100*(i+1)])\n",
    "\n",
    "for i in range(7, 10):\n",
    "    print(f\"Process the data for index = {i}\")\n",
    "    for query in tqdm(queries_list[i]):\n",
    "        tweets = client.search_recent_tweets(query=query, \n",
    "                                             tweet_fields=['author_id', 'entities'],\n",
    "                                             max_results=100)\n",
    "        temp_df = CreateDataFrame(tweets)\n",
    "        df_list.append(temp_df)\n",
    "        tagged_df_list.append(GetTaggedTweet(temp_df))\n",
    "\n",
    "\n",
    "    tweet_data = pd.concat(df_list)\n",
    "    tagged_tweet_data = pd.concat(tagged_df_list)\n",
    "    print(f\"  Get a whole dataset of length {len(tweet_data)}\")\n",
    "    print(f\"  Get a tagged dataset of length {len(tagged_tweet_data)}\")\n",
    "    print(f\"  Output the data...\")\n",
    "    tweet_data.to_csv(\"./data/tweets_\"+str(i)+\".csv\", index=False)\n",
    "    tagged_tweet_data.to_csv(\"./data/tagged_tweets_\"+str(i)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59d73c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and concat them into one file\n",
    "data_df_list = []\n",
    "tagged_data_df_list = []\n",
    "for i in range(10):\n",
    "    tweet_data = pd.read_csv(\"./data/tweets_\"+str(i)+\".csv\")\n",
    "    tagged_tweet_data = pd.read_csv(\"./data/tagged_tweets_\"+str(i)+\".csv\")\n",
    "    data_df_list.append(tweet_data)\n",
    "    tagged_data_df_list.append(tagged_tweet_data)\n",
    "\n",
    "data_df = pd.concat(data_df_list)\n",
    "tagged_data_df = pd.concat(tagged_data_df_list)\n",
    "data_df.to_csv(\"./data/tweets.csv\", index=False)\n",
    "tagged_data_df.to_csv(\"./data/tagged_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bddba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get a whole dataset of length 219989\n",
      "Get a tagged dataset of length 34980\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get a whole dataset of length {len(data_df)}\")\n",
    "print(f\"Get a tagged dataset of length {len(tagged_data_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63be604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
